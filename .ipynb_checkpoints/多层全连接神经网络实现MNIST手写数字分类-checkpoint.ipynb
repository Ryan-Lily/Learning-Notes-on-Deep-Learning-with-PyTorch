{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#简单的三层全连接神经网络\n",
    "import torch.nn as nn\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden_1)\n",
    "        self.layer2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.layer3 = nn.Linear(n_hidden_2, out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加激活函数的三层全连接神经网络\n",
    "import torch.nn as nn\n",
    "\n",
    "class ActivationNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(ActivationNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2), nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加批标准化的三层全连接神经网络\n",
    "import torch.nn as nn\n",
    "\n",
    "class BatchNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hiddden_2, out_dim):\n",
    "        super(BatchNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.BatchNorm1d(n_hidden_1), nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2), nn.BatchNorm1d(n_hidden_2), nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train Loss: 0.752108, Train Acc: 0.814549, Eval Loss: 0.362331, Eval Acc: 0.898686\n",
      "epoch: 1, Train Loss: 0.354782, Train Acc: 0.898321, Eval Loss: 0.307050, Eval Acc: 0.911923\n",
      "epoch: 2, Train Loss: 0.323360, Train Acc: 0.907633, Eval Loss: 0.290861, Eval Acc: 0.915904\n",
      "epoch: 3, Train Loss: 0.308949, Train Acc: 0.910997, Eval Loss: 0.281309, Eval Acc: 0.919486\n",
      "epoch: 4, Train Loss: 0.300948, Train Acc: 0.913479, Eval Loss: 0.274520, Eval Acc: 0.919686\n",
      "epoch: 5, Train Loss: 0.295583, Train Acc: 0.915312, Eval Loss: 0.269900, Eval Acc: 0.920979\n",
      "epoch: 6, Train Loss: 0.291256, Train Acc: 0.916694, Eval Loss: 0.267166, Eval Acc: 0.922472\n",
      "epoch: 7, Train Loss: 0.287689, Train Acc: 0.918460, Eval Loss: 0.263566, Eval Acc: 0.922671\n",
      "epoch: 8, Train Loss: 0.283986, Train Acc: 0.919243, Eval Loss: 0.261514, Eval Acc: 0.925060\n",
      "epoch: 9, Train Loss: 0.282034, Train Acc: 0.920293, Eval Loss: 0.259041, Eval Acc: 0.926055\n",
      "epoch: 10, Train Loss: 0.279799, Train Acc: 0.921992, Eval Loss: 0.257587, Eval Acc: 0.925657\n",
      "epoch: 11, Train Loss: 0.277938, Train Acc: 0.921958, Eval Loss: 0.256829, Eval Acc: 0.926055\n",
      "epoch: 12, Train Loss: 0.276638, Train Acc: 0.922142, Eval Loss: 0.254788, Eval Acc: 0.928045\n",
      "epoch: 13, Train Loss: 0.274967, Train Acc: 0.923441, Eval Loss: 0.253091, Eval Acc: 0.927548\n",
      "epoch: 14, Train Loss: 0.273049, Train Acc: 0.922924, Eval Loss: 0.250717, Eval Acc: 0.929140\n",
      "epoch: 15, Train Loss: 0.272030, Train Acc: 0.923791, Eval Loss: 0.250342, Eval Acc: 0.930235\n",
      "epoch: 16, Train Loss: 0.271136, Train Acc: 0.923974, Eval Loss: 0.248548, Eval Acc: 0.930434\n",
      "epoch: 17, Train Loss: 0.270062, Train Acc: 0.923891, Eval Loss: 0.248672, Eval Acc: 0.930533\n",
      "epoch: 18, Train Loss: 0.269345, Train Acc: 0.924923, Eval Loss: 0.246890, Eval Acc: 0.931230\n",
      "epoch: 19, Train Loss: 0.268238, Train Acc: 0.924507, Eval Loss: 0.246725, Eval Acc: 0.930533\n"
     ]
    }
   ],
   "source": [
    "#使用MNIST数据集训练网络\n",
    "#导入要用的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "#定义超参数\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 20\n",
    "\n",
    "#定义数据预处理函数\n",
    "data_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "#通过torchvision.datasets.MNIST()导入数据集\n",
    "train_set = torchvision.datasets.MNIST(root = './data', train = True, transform = data_tf, download = True)\n",
    "test_set = torchvision.datasets.MNIST(root = './data', train = False, transform = data_tf, download = True)\n",
    "\n",
    "#使用torch.utils.data.DataLoader()建立一个数据迭代器\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle = True, batch_size = batch_size, num_workers = 2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle = False, batch_size = batch_size, num_workers = 2)\n",
    "\n",
    "#导入网络\n",
    "import net\n",
    "model = net.SimpleNet(28*28, 300, 100, 10)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "#定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "#训练神经网络\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    for im, label in train_loader:\n",
    "        im = im.view(im.size(0), -1)\n",
    "        im = Variable(im)        \n",
    "        label = Variable(label)\n",
    "        \n",
    "        #前向传播\n",
    "        output = model(im)\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        #反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #记录误差\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        #计算分类的准确率\n",
    "        _, pred = output.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct /im.shape[0]\n",
    "        train_acc += acc\n",
    "    losses.append(train_loss / len(train_loader))\n",
    "    acces.append(train_acc / len(train_loader))\n",
    "    \n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    model.eval()\n",
    "    for im, label in test_loader:\n",
    "        im = im.view(im.size(0), -1)\n",
    "        im = Variable(im)\n",
    "        label = Variable(label)\n",
    "        \n",
    "        #前向传播\n",
    "        output = model(im)\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        #反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #记录误差\n",
    "        eval_loss += loss.item()\n",
    "        \n",
    "        #记录准确率\n",
    "        _, pred = output.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / im.shape[0]\n",
    "        eval_acc += acc\n",
    "        \n",
    "    eval_losses.append(eval_loss / len(test_loader))\n",
    "    eval_acces.append(eval_acc / len(test_loader))\n",
    "    print('epoch: {}, Train Loss: {:.6f}, Train Acc: {:.6f}, Eval Loss: {:.6f}, Eval Acc: {:.6f}'.format(epoch, train_loss / len(train_loader), train_acc / len(train_loader), eval_loss / len(test_loader), eval_acc / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
